# 商务出行智能规划系统 - 测试方案

## 概述

本测试方案基于PRD文档和评估指标，为商务出行智能规划系统提供了完整的自动化测试框架。测试方案包含42个测试点，覆盖系统的所有核心功能模块。

## 文件结构

```
evaluation/
├── README.md                    # 本文件，测试方案说明
├── metric.json                  # 评估指标定义
├── detailed_test_plan.json      # 详细测试计划
├── inputs/                      # 测试输入文件目录
│   ├── startup_test.in          # 程序启动测试输入
│   ├── create_trip_test.in      # 创建行程测试输入
│   ├── valid_city_test.in       # 有效城市识别测试输入
│   ├── invalid_city_test.in     # 无效城市验证测试输入
│   ├── integer_hours_test.in    # 整数小时支持测试输入
│   ├── decimal_hours_test.in    # 小数小时支持测试输入
│   ├── time_constraint_*.in     # 时间约束相关测试输入
│   ├── template_*.in            # 模板功能测试输入
│   ├── *_optimal_test.in        # 优化目标测试输入
│   ├── conflict_*.in            # 冲突检测测试输入
│   ├── system_stability_test.in # 系统稳定性测试输入
│   └── ...                     # 其他测试输入文件
├── expected_outputs/            # 期望输出文件目录
│   └── expected_trip_export.md  # 期望的Markdown导出文件
└── tests/                       # 单元测试目录
    └── test_file_export.py      # 文件导出功能单元测试
```

## 测试类型

### 1. Shell交互测试 (shell_interaction)
- **数量**: 40个测试点
- **用途**: 测试需要用户与命令行进行真实交互的功能
- **执行方式**: 通过标准输入模拟用户操作
- **示例**: 程序启动、菜单导航、数据输入验证等

### 2. 单元测试 (unit_test)
- **数量**: 1个测试点
- **用途**: 测试可以通过直接调用源代码函数进行验证的功能
- **执行方式**: 使用pytest框架
- **示例**: 文件导出功能验证

### 3. 文件比较测试 (file_comparison)
- **数量**: 1个测试点
- **用途**: 验证程序生成的输出文件是否正确
- **执行方式**: 与期望输出文件进行比较
- **示例**: Markdown格式导出验证

## 测试覆盖范围

### 核心功能模块
1. **程序启动与界面** (2个测试点)
   - 程序启动验证
   - 创建新行程功能

2. **行程信息管理** (8个测试点)
   - 城市输入验证（有效/无效）
   - 停留时长设置（整数/小数小时）
   - 时间窗口约束设置
   - 行程模板保存/加载

3. **交通方案生成** (8个测试点)
   - 交通数据显示（高铁/航班）
   - 优化目标选择（时间/成本/均衡）
   - 交通偏好设置
   - 中转次数限制

4. **冲突检测** (6个测试点)
   - 基础冲突检测功能
   - 硬冲突识别（高铁转飞机/飞机转高铁）
   - 软冲突识别（休息时间不足）
   - 冲突解决方案建议

5. **决策分析** (3个测试点)
   - 多属性评估
   - 量化评分
   - 方案优先级排序

6. **导出功能** (6个测试点)
   - Markdown格式导出
   - 文件保存验证
   - 行程摘要生成（距离/时间费用/关键节点）

7. **用户界面** (6个测试点)
   - 菜单体系（层级结构/返回导航）
   - 输入验证（数字/菜单选择）
   - 日期格式支持（标准/相对格式）

8. **系统质量** (3个测试点)
   - 行程保存/加载功能
   - 系统稳定性测试
   - 用户体验友好性

## 执行方式

### 1. 手动执行单个测试
```bash
# Shell交互测试
python src/main.py < evaluation/inputs/startup_test.in

# 单元测试
pytest evaluation/tests/test_file_export.py::test_file_save_verification

# 文件比较测试
python src/main.py < evaluation/inputs/markdown_export_test.in
# 然后比较生成的文件与expected_outputs/expected_trip_export.md
```

### 2. 批量执行测试
```bash
# 执行所有单元测试
pytest evaluation/tests/

# 执行特定类型的测试
for test_file in evaluation/inputs/*.in; do
    echo "执行测试: $test_file"
    python src/main.py < "$test_file"
done
```

## 评分标准

每个测试点采用3级评分制：
- **2分**: 完全满足要求，功能正常工作
- **1分**: 基本满足要求，但存在小问题
- **0分**: 不满足要求或功能不可用

总分计算：各测试点得分 × 对应权重，然后求和

## 测试数据说明

### 输入文件格式
- 每行代表一个用户输入
- 按照程序交互流程顺序排列
- 包含各种边界情况和异常输入

### 期望输出
- 基于PRD要求定义的标准输出格式
- 包含必要的功能验证点
- 考虑了用户体验和界面友好性

## 注意事项

1. **环境要求**: 确保Python环境已安装所需依赖包
2. **数据准备**: 某些测试需要预先存在的数据文件
3. **执行顺序**: 部分测试之间存在依赖关系，建议按顺序执行
4. **清理工作**: 测试完成后及时清理生成的临时文件

## 扩展说明

本测试方案设计为可扩展的框架：
- 可以轻松添加新的测试用例
- 支持不同类型的测试方法
- 便于集成到CI/CD流程中
- 提供详细的测试报告和分析

---
*测试方案版本: 1.0*  
*最后更新: 2024-12-01*