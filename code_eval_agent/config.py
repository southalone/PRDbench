import os
import uuid
from datetime import datetime
from google.adk.models.lite_llm import LiteLlm
from lite_llm_wrapper import LiteLlmWithSleep

# åŸºç¡€æ¨¡å‹é…ç½®
BASIC_MODEL =LiteLlmWithSleep(
        model="openai/gemini-2.5-pro",
        api_base='https://aigc.sankuai.com/v1/openai/native',
        api_key='1873925539543834701',
        max_tokens=32768,
        temperature=0.1
    )

friday_model_dict = {
    "claude_3_7_sonnet": LiteLlmWithSleep(
        # model="openai/anthropic.claude-3.7-sonnet",
        # api_base='https://aigc.sankuai.com/v1/openai/native',
        # api_key='1873925539543834701',
        model="openai/claude-3-7-sonnet-20250219",
        api_base='https://api.toiotech.com/v1',
        api_key='sk-nw5G71pE0RgR4ew85fdYUDWTYxdFma0M4aQoUTuxNrXNXFqP',
        # max_completion_tokens=32000,
        max_tokens_threshold=131072-32000-1000,
        enable_compression=True,
        temperature=0.1
    ),
    "gemini": LiteLlmWithSleep(
        model="openai/gemini-2.5-pro",
        api_base='https://aigc.sankuai.com/v1/openai/native',
        api_key='1873925539543834701',
        max_tokens=32768,
        temperature=0.1
    ),
    'gpt_5':LiteLlmWithSleep(
    model="openai/gpt-5",
    api_base='https://api.toiotech.com/v1',
    api_key='sk-LfUBAupPQCgffAEkCb61278d4c734225A7533778B123CbBa',
    # max_completion_tokens=32000,
    max_tokens_threshold=256_000-32000,
    enable_compression=True
),
"qwen3_coder": LiteLlmWithSleep(
    model="openai/qwen3-coder-480b-a35b-instruct",
    api_base='https://api.toiotech.com/v1',
    api_key='sk-nw5G71pE0RgR4ew85fdYUDWTYxdFma0M4aQoUTuxNrXNXFqP',
    # max_completio[n_tokens=32000,
    max_tokens_threshold=256_000-32000,
    enable_compression=True,
    temperature=0.1,
    presence_penalty=1.2
)
}



# ç”Ÿæˆéšæœºæ‰§è¡ŒID
def generate_execution_id():
    """ç”Ÿæˆå”¯ä¸€çš„æ‰§è¡ŒID"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    unique_id = str(uuid.uuid4())[:8]
    return f"exec_{timestamp}_{unique_id}"

# å½“å‰æ‰§è¡ŒID
CURRENT_EXECUTION_ID = generate_execution_id()

# æœ¬åœ°MCPæœåŠ¡å™¨é…ç½®
# PYTHON_INTERPRETER_MCP_URL = "http://localhost:9001/python-interpreter"
# FILE_OPERATIONS_MCP_URL = "http://localhost:8002/file-operations"
# SYSTEM_OPERATIONS_MCP_URL = "http://localhost:8003/system-operations"

import os

# ç«¯å£ç¯å¢ƒå˜é‡åç§°
PYTHON_INTERPRETER_PORT = os.getenv("PYTHON_INTERPRETER_PORT", "9001")
FILE_OPERATIONS_PORT = os.getenv("FILE_OPERATIONS_PORT", "8002")
SYSTEM_OPERATIONS_PORT = os.getenv("SYSTEM_OPERATIONS_PORT", "8003")

PYTHON_INTERPRETER_MCP_URL = f"http://localhost:{PYTHON_INTERPRETER_PORT}/python-interpreter"
FILE_OPERATIONS_MCP_URL = f"http://localhost:{FILE_OPERATIONS_PORT}/file-operations"
SYSTEM_OPERATIONS_MCP_URL = f"http://localhost:{SYSTEM_OPERATIONS_PORT}/system-operations"


# MCPè¿æ¥é…ç½®
MCP_SSE_TIMEOUT = 30
MAX_ITERATIONS = 10

# ç³»ç»Ÿé…ç½®
SYSTEM_NAME = "LocalCodeAgent"
BASE_WORKSPACE_DIR = "/tmp/code_agent_workspace"

# æ”¯æŒç¯å¢ƒå˜é‡è¦†ç›–å·¥ä½œç›®å½•ï¼Œæ–¹ä¾¿æœ¬åœ°æµ‹è¯•
# ä½¿ç”¨æ–¹æ³•ï¼šexport CODE_AGENT_WORKSPACE_DIR=/path/to/your/workspace
WORKSPACE_DIR = os.getenv('CODE_AGENT_WORKSPACE_DIR', BASE_WORKSPACE_DIR)

# å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè½¬æ¢ä¸ºç»å¯¹è·¯å¾„
if not os.path.isabs(WORKSPACE_DIR):
    WORKSPACE_DIR = os.path.abspath(WORKSPACE_DIR)

# å®‰å…¨é…ç½®
ALLOWED_EXTENSIONS = ['.py', '.txt', '.md', '.json', '.yaml', '.yml', '.csv', '.sql', '.in', '.jsonl']
MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB
SANDBOX_MODE = True


# æ˜¯å¦å¯ç”¨è·¯å¾„é™åˆ¶
ENABLE_PATH_RESTRICTION = os.getenv('ENABLE_PATH_RESTRICTION', 'true').lower() == 'true'

print(f"ğŸš€ å½“å‰æ‰§è¡ŒID: {CURRENT_EXECUTION_ID}")
print(f"ğŸ“ å·¥ä½œç©ºé—´è·¯å¾„: {WORKSPACE_DIR}") 